# VisionFMï¼šç”¨äºé€šç”¨çœ¼ç§‘äººå·¥æ™ºèƒ½çš„è§†è§‰åŸºç¡€æ¨¡å‹

VisionFM å®˜æ–¹å®ç° - ä¸€ä¸ª multimodal multitask vision foundation modelï¼Œä½¿ç”¨æ¥è‡ªè¶…è¿‡ 50 ä¸‡å—è¯•è€…çš„ 340 ä¸‡å¼ çœ¼ç§‘å›¾åƒè¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥å®ç°é€šç”¨çœ¼ç§‘äººå·¥æ™ºèƒ½ã€‚VisionFM èƒ½å¤Ÿå¤„ç†å…«ç§å¸¸è§çš„çœ¼ç§‘æˆåƒæ¨¡å¼ï¼ŒåŒ…æ‹¬çœ¼åº•æ‘„å½±ã€å…‰å­¦ç›¸å¹²æ–­å±‚æ‰«æ (OCT)ã€çœ¼åº•è§å…‰è¡€ç®¡é€ å½± (FFA)ã€è£‚éš™ç¯ã€B å‹è¶…å£°ã€å¤–çœ¼æˆåƒã€MRI å’Œè¶…å£°ç”Ÿç‰©æ˜¾å¾®é•œ (UBM)ï¼Œå¹¶å¯åº”ç”¨äºè§£å†³å„ç§çœ¼ç§‘ AI ä»»åŠ¡ï¼Œå¦‚çœ¼éƒ¨ç–¾ç—…è¯†åˆ«ã€ç–¾ç—…è¿›å±•é¢„æµ‹ã€ç–¾ç—…è¡¨å‹å’Œè§£å‰–æ ‡å¿—çš„åˆ†å‰²å’Œæ£€æµ‹ï¼Œä»¥åŠå…¨èº«ç”Ÿç‰©æ ‡å¿—ç‰©å’Œç–¾ç—…é¢„æµ‹ã€‚VisionFM çš„åŠŸèƒ½å¯ä»¥é€šè¿‡æ–°æˆåƒæ¨¡å¼çš„è‡ªç›‘ç£é¢„è®­ç»ƒå’Œæ–°ä¸´åºŠä»»åŠ¡çš„ç›‘ç£å¾®è°ƒè¿›ä¸€æ­¥æ‰©å±•ï¼Œæœ‰å¯èƒ½è§£å†³å„ç§å…¨çƒçœ¼ç§‘ç–¾ç—…å’Œä¸åŒçš„ä¸´åºŠæŒ‘æˆ˜ã€‚

## æœ€æ–°æ¶ˆæ¯

- \[2024/11\] ğŸ‰ æ­å–œï¼VisionFM å·²åœ¨ [NEJM AI](https://ai.nejm.org/doi/full/10.1056/AIoa2300221) ä¸Šå‘è¡¨ã€‚

- \[2024/05\] å¾®è°ƒä»£ç å·²å‘å¸ƒï¼ŒåŒæ—¶å‘å¸ƒäº†åœ¨å…«ä¸ªå…¬å…±å¤šç±»ç–¾ç—…è¯†åˆ«æ•°æ®é›†ä¸Šçš„å¾®è°ƒæƒé‡

## å¼•ç”¨

å¦‚æœæ‚¨è®¤ä¸ºè¿™ä¸ªä»“åº“æœ‰ç”¨ï¼Œè¯·è€ƒè™‘å¼•ç”¨è¿™ç¯‡è®ºæ–‡ï¼š

```text
@article{qiu2024development,
  title={Development and validation of a multimodal multitask vision foundation model for generalist ophthalmic artificial intelligence},
  author={Qiu, Jianing and Wu, Jian and Wei, Hao and Shi, Peilun and Zhang, Minqing and Sun, Yunyun and Li, Lin and Liu, Hanruo and Liu, Hongyi and Hou, Simeng and others},
  journal={NEJM AI},
  volume={1},
  number={12},
  pages={AIoa2300221},
  year={2024},
  publisher={Massachusetts Medical Society}
}
```

## 0\. å®‰è£…ç¯å¢ƒ

ä½¿ç”¨ conda å‘½ä»¤åˆ›å»ºç¯å¢ƒï¼š

```shell
conda create -n vfm python=3.8
conda activate vfm
```

å®‰è£…ä¾èµ–ï¼š

```shell
git clone https://github.com/ABILab-CUHK/VisionFM.git
cd VisionFM
pip install -r requirements.txt
```

## 1\. å¾®è°ƒ

å¦‚æœæ‚¨æƒ³åˆ©ç”¨æˆ‘ä»¬çš„æƒé‡åœ¨æ‚¨çš„æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè¯·å‚è€ƒæ­¤ [è¯´æ˜](./Fine-tuning/README.md)ã€‚

## 2\. é¢„è®­ç»ƒ

åœ¨æ­¤æ­¥éª¤ä¸­ï¼Œæ‚¨å¯ä»¥åœ¨è‡ªå·±çš„æ•°æ®ä¸Šé¢„è®­ç»ƒè‡ªå·±çš„ VisionFM ç¼–ç å™¨ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹è¯´æ˜å¼€å§‹é¢„è®­ç»ƒã€‚

### 2.1. å‡†å¤‡é¢„è®­ç»ƒæ•°æ®é›†

åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† `8` ç§æ¨¡å¼ï¼š`Fundus, OCT, External Eye, UBM, B-Ultrasound, MRI, Silt Lamp, and FFA`ã€‚ å¯¹äºæ¯ç§æ¨¡å¼ï¼Œä¾‹å¦‚ Fundusï¼Œå…¶æ•°æ®è·¯å¾„åº”ä¸º `/xxx/Fundus/`ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰ Fundus å›¾åƒ å…·æœ‰ç›¸åŒæˆ–ä¸åŒçš„åç¼€ï¼š

```
.
â”œâ”€â”€ /dst_dir/Fundus/
â”‚   â”œâ”€â”€ 1.jpg
â”‚   â”œâ”€â”€ 2.png
â”‚   â””â”€â”€ ....
â”œâ”€â”€ /dst_dir/OCT/
â”‚   â”œâ”€â”€ 1.png
â”‚   â”œâ”€â”€ 2.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
 
```

å¦‚æœæ‚¨æ‰‹å¤´æ²¡æœ‰çœ¼åº•ç…§ç‰‡ï¼Œå¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆéšæœºå›¾åƒï¼š

```shell
cd evaluation
python random_data.py --task pretrain --dst_dir ../dataset/pretrain_random
```

### 2.2. é¢„è®­ç»ƒ VisionFM ç¼–ç å™¨

1. åœ¨ `Fundus` æ¨¡å¼ä¸Šè®­ç»ƒ `vit-base`ï¼š

```shell
# è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥è®­ç»ƒ Fundus ç¼–ç å™¨
CUDA_VISIBLE_DEVICES=0,1,2,3 nohup python3 -m torch.distributed.launch --nnodes 1 --node_rank 0 --nproc_per_node=4 --master_addr=127.0.0.1 --master_port=29500 main_pretrain.py \
--local-rank=0 \
--data_path ./dataset/pretrain_random \
--modality Fundus \ 
--norm_last_layer true \
--epochs 400 \
--batch_size_per_gpu 12 \
--shared_head true \
--out_dim 8192 \
--output_dir ./results \
--global_crops_scale 0.32 1.0 \
--pred_ratio 0 0.3 \
--pred_ratio_var 0 0.2 \
--name Train_Random_Fundus \
--load_pretrain > train_fundus.log 2>&1 &
# or 
bash train_vitb_fundus.sh # åŒ…å«ç›¸åŒçš„å‘½ä»¤

# æ³¨æ„ï¼šé»˜è®¤çš„ batch size æ˜¯ 128ï¼Œbatch_size=12 ä»…ç”¨äºè°ƒè¯•ã€‚
```

é€šè¿‡æ›´æ”¹æ¨¡å¼ï¼Œå¯ä»¥è®­ç»ƒä¸åŒçš„ VisionFM ç¼–ç å™¨ã€‚

## 3\. ä¸ºä¸‹æ¸¸ä»»åŠ¡è®­ç»ƒè§£ç å™¨

### 3.1. ä¸‹è½½ VisionFM çš„é¢„è®­ç»ƒæƒé‡

è¯·æ ¹æ®æ‚¨æƒ³è¦è¿›è¡Œç ”ç©¶çš„æ¨¡å¼ä¸‹è½½ç›¸åº”çš„æ¨¡å‹æƒé‡ã€‚

|æ¨¡å¼|Google Drive|
|-|-|
|Fundus|[Download](https://drive.google.com/file/d/13uWm0a02dCWyARUcrCdHZIcEgRfBmVA4/view?usp=sharing)|
|OCT|[Download](https://drive.google.com/file/d/1o6E-ine2QLx2pxap-c77u-SU0FjxwypA/view?usp=sharing)|
|FFA|[Download](https://drive.google.com/file/d/128izBUNV00Ojb9w9Dq3GhBvhWqzU-mla/view?usp=sharing)|
|Ultrasound|[Download](https://drive.google.com/file/d/1IlD0snowxdEVvxmiIBZGR0D9uOcrCT2D/view?usp=sharing)|
|External Eye|[Download](https://drive.google.com/file/d/16zGHTD4ZcGAYW382kKHBw3TU6D1OtvTD/view?usp=sharing)|
|Silt Lamp|[Download](https://drive.google.com/file/d/1pemWDkGoZYlqLQ6ooFINktyk8xnv9wY_/view?usp=sharing)|
|MRI|[Download](https://drive.google.com/file/d/1fcfylnOWhfnZHBAKT9pQPufyS5ZYCXu0/view?usp=sharing)|
|UBM|[Download](https://drive.google.com/file/d/1q2fVOgFBnWNu1BsXaza1A-OIcCiifNUQ/view?usp=sharing)|

### 3.2.è®­ç»ƒåˆ†ç±»è§£ç å™¨ \[å¤šæ¨¡æ€\]

`å¤šæ¨¡æ€` æ„å‘³ç€è§£ç å™¨æ˜¯åœ¨ä¸åŒæ¨¡æ€ä¸ŠåŒæ—¶è®­ç»ƒçš„ã€‚è€ƒè™‘åˆ°ä¸åŒç¼–ç å™¨çš„å­˜åœ¨ï¼ˆæ¯ç§æ¨¡æ€éƒ½æœ‰è‡ªå·±çš„ç¼–ç å™¨ï¼‰ï¼Œ æˆ‘ä»¬é‡‡ç”¨ä¸¤é˜¶æ®µæµæ°´çº¿ï¼š`ä»ä¸åŒæ¨¡æ€çš„ VisionFM ç¼–ç å™¨ä¸­é¢„æå–ç‰¹å¾` å’Œ `ä½¿ç”¨èšåˆçš„å›¾åƒç‰¹å¾è®­ç»ƒè§£ç å™¨`ï¼š

å¯¹äºç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®æ¨¡æ€æå–å›¾åƒç‰¹å¾ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ Fundus å’Œ OCT ç¼–ç å™¨åˆ†åˆ«æå– Fundus å’Œ OCT ç‰¹å¾ã€‚ ç„¶åï¼Œå¯¹äºç¬¬äºŒæ­¥ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹ä½¿ç”¨ä»è¿™ä¸¤ç§æ¨¡æ€ä¸­æå–çš„ç»„åˆç‰¹å¾æ¥è®­ç»ƒè§£ç å™¨ã€‚

#### 3.2.1. å‡†å¤‡æ•°æ®é›†

è¯·å°†æ‚¨çš„æ•°æ®é›†ç»„ç»‡æˆä»¥ä¸‹ç›®å½•ç»“æ„ï¼ˆæˆ‘ä»¬ç§°è¿™ç§ç›®å½•ç»“æ„æ ·å¼ä¸º `vfm`ï¼‰ï¼š

```
.
â”œâ”€â”€ /XXX/FundusClassification/
â”‚   â”œâ”€â”€ dataset_A/
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”‚   â”œâ”€â”€ 1.png
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2.png
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ training_labels.txt
â”‚   â”‚   â””â”€â”€ test_labels.txt
â”‚   â”œâ”€â”€ dataset_B/
â”‚   â”‚   â””â”€â”€ ....
â”‚   â””â”€â”€ ....
â”œâ”€â”€ /XXX/OCTClassification/
â”‚   â”œâ”€â”€ dataset_A/
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”‚   â”œâ”€â”€ 1.png
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2.png
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ training_labels.txt
â”‚   â”‚   â””â”€â”€ test_labels.txt
â”‚   â”œâ”€â”€ dataset_B/
â”‚   â”‚   â””â”€â”€ ....
â”‚   â””â”€â”€ ....
...
```

ç›¸åº”çš„ `training_labels.txt` å’Œ `test_labels.txt` ç»„ç»‡å¦‚ä¸‹ä½œä¸ºç¤ºä¾‹ï¼š

```
# ç±»åˆ«åˆ—è¡¨: ['Healthy', 'DR-1', 'DR-2', 'DR-3', 'DR-4', 'DR', 'Glaucoma', 'AMD', 'Cataract', 'Hypertensive Retinopathy', 'Retinal Vein Occlusion', 'Myopia', 'Retinal Detachment']
# åœ¨ training_labels.txt ä¸­
# æ³¨æ„: å»ºè®®ä½¿ç”¨å¤šæ ‡ç­¾æ ·å¼ï¼ˆé one-hotï¼‰æ¥æ ‡è®°ï¼Œä»¥æ–¹ä¾¿è¯†åˆ«æ ‡è®°æœ‰å¤šç§ç–¾ç—…çš„å›¾åƒï¼ŒåŒæ—¶ç®€åŒ–åˆ†çº§å’Œéåˆ†çº§æ•°æ®çš„ä½¿ç”¨ã€‚
training/1.jpg;0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0
training/2.jpg;0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0
```

æ‚¨å¯ä»¥ä¸‹è½½æˆ‘ä»¬é¢„å¤„ç†çš„å…¬å…± [æ•°æ®é›†](https://drive.google.com/file/d/1QShoYrkhZetF41vmFuf6ds3I1W05YONk/view?usp=drive_link)ï¼ˆåŒ…å« IDRiD å’Œ OCTID æ•°æ®é›†ï¼‰æ¥å¼€å§‹è®­ç»ƒã€‚ è§£å‹ä¸‹è½½çš„æ•°æ®é›†åï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹ç»“æ„ç»„ç»‡æ•°æ®é›†ï¼š

```text
./dataset/ProcessedDatasets/MultiModalCls/IDRiD
./dataset/ProcessedDatasets/MultiModalCls/OCTID
```

æˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆéšæœºæ•°æ®é›†ï¼š

```shell
python evaluation/random_data.py --task multi_cls --dst_dir ./dataset/multi_cls_random
```

#### 3.2.2. ç‰¹å¾æå–

ä»¥ä¸‹å‘½ä»¤ä½¿ç”¨é¢„è®­ç»ƒçš„ VisionFM ç¼–ç å™¨æå–å›¾åƒç‰¹å¾ï¼š

```shell
#cd evaluation
#åˆ†åˆ«é€šè¿‡ Fundus å’Œ OCT ç¼–ç å™¨æå– Fundus å’Œ OCT ç‰¹å¾
#CUDA_VISIBLE_DEVICES=0 nohup python evaluation/extract_features.py \
# æå– Fundus ç‰¹å¾
CUDA_VISIBLE_DEVICES=1,2 nohup python3 -m torch.distributed.launch --nnodes 1 --node_rank 0 --nproc_per_node=2 --master_port=29503 evaluation/extract_features.py \
--pretrained_weights ./pretrain_weights/VFM_Fundus_weights.pth \
--batch_size_per_gpu 768 \
--data_path ./dataset/multi_cls_random/FundusClassificationMulti/ \
--modality Fundus \
--dst_root ./dataset/multi_cls_random/FunClsFeat/ > extract_feats.log 2>&1 &

# æå– OCT ç‰¹å¾
CUDA_VISIBLE_DEVICES=1,2 nohup python3 -m torch.distributed.launch --nnodes 1 --node_rank 0 --nproc_per_node=2 --master_port=29503 evaluation/extract_features.py \
--pretrained_weights ./pretrain_weights/VFM_OCT_weights.pth \
--batch_size_per_gpu 768 \
--data_path ./dataset/multi_cls_random/OCTClassificationMulti/ \
--modality OCT \
--dst_root ./dataset/multi_cls_random/OCTClsFeat/ > extract_feats.log 2>&1 &

# å¯¹äºæä¾›çš„é¢„å¤„ç†æ•°æ®é›†ï¼Œæ‚¨åº”è¯¥è®¾ç½®ä»¥ä¸‹å‚æ•°ï¼š
--data_path ./dataset/ProcessedDatasets/MultiModalCls/FundusClassificationMulti/
--dst_root ./dataset/ProcessedDatasets/MultiModalCls/FunClsFeat/
# æˆ–è€…
--data_path ./dataset/ProcessedDatasets/MultiModalCls/OCTClassificationMulti/
--dst_root ./dataset/ProcessedDatasets/MultiModalCls/OCTClsFeat/
```

#### 3.2.3. åŸºäºæå–çš„å¤šæ¨¡æ€ç‰¹å¾è®­ç»ƒè§£ç å™¨

ç„¶åï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤è®­ç»ƒåˆ†ç±»è§£ç å™¨ï¼š

```shell
#cd evaluation
CUDA_VISIBLE_DEVICES=0 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 evaluation/train_cls_multi_decoder.py \
--name train_debug \ 
--output_dir ./results \
--datasets FunClsFeat OCTClsFeat \
--data_path ./dataset/multi_cls_random/ \
--batch_size_per_gpu 8192 > train_cls_multi.log 2>&1 &
```

### 3.3. è®­ç»ƒåˆ†ç±»è§£ç å™¨ \[å•æ¨¡æ€\]

æ­¤ä»»åŠ¡ä¸»è¦å…³æ³¨å•æ¨¡æ€ï¼Œä¾‹å¦‚åŸºäº Fundus çš„ DR åˆ†çº§ä»»åŠ¡ã€‚

#### 3.3.1. å‡†å¤‡æ•°æ®é›†

è¯·å°†æ‚¨çš„æ•°æ®é›†ç»„ç»‡æˆä»¥ä¸‹ç›®å½•ç»“æ„ï¼ˆæˆ‘ä»¬ç§°è¿™ç§ç›®å½•ç»“æ„æ ·å¼ä¸º `vfm`ï¼‰ï¼š

```
.
â”œâ”€â”€ /XXX/FundusClassification/ # æ‰€æœ‰æ•°æ®é›†åº”ä¸ºåŒä¸€ä»»åŠ¡ï¼Œå…·æœ‰ç›¸åŒçš„ç±»åˆ«å®šä¹‰
â”‚   â”œâ”€â”€ dataset_A/
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”‚   â”œâ”€â”€ 1.png
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2.png
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ training_labels.txt
â”‚   â”‚   â””â”€â”€ test_labels.txt
â”‚   â”œâ”€â”€ dataset_B/
â”‚   â”‚   â””â”€â”€ ....
â”‚   â””â”€â”€ ....
â”œâ”€â”€ /XXX/OCTClassification/
â”‚   â”œâ”€â”€ dataset_A/
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”‚   â”œâ”€â”€ 1.png
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2.png
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ training_labels.txt
â”‚   â”‚   â””â”€â”€ test_labels.txt
â”‚   â”œâ”€â”€ dataset_B/
â”‚   â”‚   â””â”€â”€ ....
â”‚   â””â”€â”€ ....
...
```

`training_labels.txt` å’Œ `test_labels.txt` åŒ…å«å›¾åƒè·¯å¾„åŠå…¶å¯¹åº”çš„æ ‡ç­¾ï¼š

```text
# åœ¨ training_labels.txt ä¸­
training/1.jpg;1
training/2.jpg;2
```

æ‚¨å¯ä»¥ä¸‹è½½æˆ‘ä»¬é¢„å¤„ç†çš„ [æ•°æ®é›†](https://drive.google.com/file/d/1QShoYrkhZetF41vmFuf6ds3I1W05YONk/view?usp=drive_link)ï¼ˆåŒ…å«å¤„ç†åçš„ IDRiD å’Œ OCTID ä»¥å¼€å§‹è®­ç»ƒã€‚ è§£å‹ä¸‹è½½çš„æ•°æ®é›†åï¼Œæ‚¨åº”è¯¥ä½¿ç”¨ä»¥ä¸‹ç»“æ„ç»„ç»‡æ•°æ®é›†ï¼š

```text
./dataset/ProcessedDatasets/SingleModalCls/FundusClassification/IDRiD 
./dataset/ProcessedDatasets/SingleModalCls/OCTClassification/OCTID
```

æˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆéšæœºæ•°æ®é›†ï¼š

```shell
python evaluation/random_data.py --task single_cls --dst_dir ./dataset/single_cls_random # ç”¨äº DR åˆ†çº§ä»»åŠ¡
```

é™¤äº†æåˆ°çš„ç›®å½•ç»“æ„ï¼ˆç§°ä¸º vfmï¼‰ï¼Œæ‚¨è¿˜å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ç›®å½•ç»“æ„ï¼ˆImageNet æ ¼å¼ï¼‰ï¼š

```test
â”œâ”€â”€ æ•°æ®æ–‡ä»¶å¤¹
    â”œâ”€â”€train
        â”œâ”€â”€class_a
        â”œâ”€â”€class_b
        â”œâ”€â”€class_c
    â”œâ”€â”€val
        â”œâ”€â”€class_a
        â”œâ”€â”€class_b
        â”œâ”€â”€class_c
    â”œâ”€â”€test
        â”œâ”€â”€class_a
        â”œâ”€â”€class_b
        â”œâ”€â”€class_c
```

å¦‚æœæ‚¨çš„æ•°æ®é›†ä»¥æ­¤ç»“æ„ç»„ç»‡ï¼Œè¯·è®¾ç½® `--dataset_format ImageNet`ã€‚

#### 3.3.2. è®­ç»ƒè§£ç å™¨

ç„¶åï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤ä¸ºåˆ†ç±»ä»»åŠ¡è®­ç»ƒè§£ç å™¨ï¼š

```shell
CUDA_VISIBLE_DEVICES=0 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 evaluation/train_cls_decoder.py \
--name single_cls_debug \
--pretrained_weights ./pretrain_weights/VFM_Fundus_weights.pth \
--output_dir ./results \
--data_path ./dataset/single_cls_random/FundusClassification/ \
--num_labels 5 \
--batch_size_per_gpu 32 > train_single_cls.log 2>&1 &

#æ³¨æ„ï¼šå¯¹äºäºŒåˆ†ç±»ä»»åŠ¡ï¼Œè¯·è®¾ç½® --num_labels 1

# å¯¹äºå¤„ç†åçš„æ•°æ®é›†ï¼šåŸºäº Fundus çš„ DR åˆ†çº§
CUDA_VISIBLE_DEVICES=0 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 evaluation/train_cls_decoder.py \
--name single_cls_debug \
--pretrained_weights ./pretrain_weights/VFM_Fundus_weights.pth \
--output_dir ./results \ 
--data_path ./dataset/ProcessedDatasets/SingleModalCls/FundusClassification  \
--num_labels 5 \
--batch_size_per_gpu 32 > train_single_cls.log 2>&1 &

# å¯¹äº ImageNet æ ¼å¼çš„æ•°æ®é›†ï¼šåŸºäº Fundus çš„ DR åˆ†çº§
CUDA_VISIBLE_DEVICES=0 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 evaluation/train_cls_decoder.py \
--name single_cls_debug \
--dataset_format ImageNet \
--pretrained_weights ./pretrain_weights/VFM_Fundus_weights.pth \
--output_dir ./results \
--data_path ./dataset/xxx/  \
--num_labels 5 \
--batch_size_per_gpu 32 > train_single_cls.log 2>&1 &

# å¯¹äºå¤„ç†åçš„æ•°æ®é›†ï¼šåŸºäº OCT çš„äºŒåˆ†ç±»ï¼ˆHealth, DRï¼‰
CUDA_VISIBLE_DEVICES=0 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 evaluation/train_cls_decoder.py \
--name single_cls_debug \
--pretrained_weights ./pretrain_weights/VFM_OCT_weights.pth \
--output_dir ./results \
--data_path ./dataset/ProcessedDatasets/SingleModalCls/OCTClassification  \
--num_labels 1 \
--modality OCT \
--batch_size_per_gpu 32 > train_single_cls.log 2>&1 &

# åœ¨è§£ç å™¨è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¯„ä¼°è®­ç»ƒå¥½çš„è§£ç å™¨
CUDA_VISIBLE_DEVICES=0 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 evaluation/train_cls_decoder.py \
--name single_cls_debug \
--pretrained_weights ./pretrain_weights/VFM_Fundus_weights.pth \
--output_dir ./results \
--data_path ./dataset/ProcessedDatasets/SingleModalCls/FundusClassification  \
--num_labels 5 \
--load_from ./results/single_cls_debug/checkpoint_teacher_linear.pth\
--test \
--batch_size_per_gpu 32 > train_single_cls.log 2>&1 &


# æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡æ·»åŠ ä¸¤ä¸ªé¢å¤–å‚æ•°æ¥åŠ è½½ RETFound æƒé‡ï¼š
--arch vit_large \
--checkpoint_key model \
```

### 3.4.è®­ç»ƒåˆ†å‰²è§£ç å™¨ \[å•æ¨¡æ€\]

åœ¨åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬ä¸ºä¸åŒçš„ä»»åŠ¡å’Œæ¨¡æ€è®­ç»ƒä¸åŒçš„è§£ç å™¨ã€‚

#### 3.4.1. å‡†å¤‡æ•°æ®é›†

è¯·å°†æ‚¨çš„æ•°æ®é›†ç»„ç»‡æˆä»¥ä¸‹ç›®å½•ç»“æ„ï¼ˆæˆ‘ä»¬ç§°è¿™ç§ç›®å½•ç»“æ„æ ·å¼ä¸º `vfm`ï¼‰ï¼š

```
â”œâ”€â”€ /dst_dir/VesselSegmentation/ # æ‰€æœ‰æ•°æ®é›†åº”ä¸ºåŒä¸€ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼Œçœ¼åº•è¡€ç®¡åˆ†å‰²
â”‚   â”œâ”€â”€ dataset_A/
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 1.png
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â””â”€â”€ labels/
â”‚   â”‚   â”‚       â”œâ”€â”€ 1.png
â”‚   â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ dataset_B/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
labels ç›®å½•ä¸­å›¾åƒçš„åƒç´ å€¼èŒƒå›´åº”ä¸º [0, C-1]ï¼Œå…¶ä¸­ C æ˜¯ç±»åˆ«æ•°ã€‚
```

æ‚¨å¯ä»¥ä¸‹è½½æˆ‘ä»¬é¢„å¤„ç†çš„å…¬å…± [æ•°æ®é›†](https://drive.google.com/file/d/1QShoYrkhZetF41vmFuf6ds3I1W05YONk/view?usp=drive_link)ï¼ˆåŒ…å« DRIVE æ•°æ®é›†ç”¨äºè¡€ç®¡åˆ†å‰²ï¼‰æ¥å¼€å§‹è®­ç»ƒã€‚ è§£å‹ä¸‹è½½çš„æ•°æ®é›†åï¼Œè¯·å°†æ•°æ®é›†ç»„ç»‡æˆä»¥ä¸‹ç»“æ„ï¼š

```text
./dataset/ProcessedDatasets/SingleModalSeg/VesselSegmentation/DRIVE 
```

æˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆéšæœºæ•°æ®é›†ï¼š

```shell
python evaluation/random_data.py --task segmentation --dst_dir ./dataset/seg_random
```

#### 3.4.2. è®­ç»ƒè§£ç å™¨

ç„¶åï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤ä¸ºåˆ†å‰²ä»»åŠ¡è®­ç»ƒè§£ç å™¨ï¼š

```shell
CUDA_VISIBLE_DEVICES=0 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29509 evaluation/train_seg_decoder.py \
--name single_seg_debug \
--pretrained_weights ./pretrain_weights/VFM_Fundus_weights.pth \
--input_size 512 \
--modality Fundus \
--num_labels 5 \
--output_dir ./results \
--data_path ./dataset/seg_random/VesselSegmentation/ \
--batch_size_per_gpu 5 > train_seg.log 2>&1 &

# å¯¹äºæä¾›çš„é¢„å¤„ç†æ•°æ®é›†ï¼Œæ‚¨åº”è¯¥è®¾ç½®ä»¥ä¸‹å‚æ•°ï¼š
CUDA_VISIBLE_DEVICES=0 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29509 evaluation/train_seg_decoder.py \
--name single_seg_debug \
--pretrained_weights ./pretrain_weights/VFM_Fundus_weights.pth \
--input_size 512 \
--modality Fundus \
--num_labels 1 \
--output_dir ./results \
--data_path ./dataset/ProcessedDatasets/SingleModalSeg/VesselSegmentation/ \
--batch_size_per_gpu 5 > train_seg.log 2>&1 &
```

### 3.5. è®­ç»ƒåœ°æ ‡æ£€æµ‹è§£ç å™¨ \[å•æ¨¡æ€\]

åœ¨æ­¤ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªè§£ç å™¨æ¥æ£€æµ‹ UBM å›¾åƒä¸Šçš„å‰æˆ¿è§’ (ACA) åœ°æ ‡ã€‚

#### 3.5.1. å‡†å¤‡æ•°æ®é›†

è¯·å°†æ•°æ®é›†ç»„ç»‡æˆä¸åˆ†å‰²ä»»åŠ¡ç›¸åŒçš„ç›®å½•ç»“æ„ï¼ˆæ ‡ç­¾çš„åç¼€åº”ä¸º .npyï¼‰ã€‚

æˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆéšæœºæ•°æ®é›†ï¼š

```shell
python evaluation/random_data.py --task landmark --dst_dir ./dataset/landmark_random
```

#### 3.5.2. è®­ç»ƒè§£ç å™¨

ç„¶åï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸ºåœ°æ ‡æ£€æµ‹ä»»åŠ¡è®­ç»ƒè§£ç å™¨ï¼š

```shell
CUDA_VISIBLE_DEVICES=0 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29508 evaluation/train_landmark_decoder.py \
--name train_landmark \
--pretrained_weights ./pretrain_weights/VFM_Fundus_weights.pth \
--output_dir ./results \
--data_path ./dataset/landmark_random/LandmarkDetection \
--batch_size_per_gpu 32  > train_landmark.log 2>&1 &
```

### 3.6. è®­ç»ƒç”Ÿç‰©æ ‡å¿—ç‰©é¢„æµ‹è§£ç å™¨ \[å¤šæ¨¡æ€\]

åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬åœ¨ Fundus å’Œ External å›¾åƒä¸Šè®­ç»ƒè§£ç å™¨ä»¥é¢„æµ‹ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚

#### 3.6.1. å‡†å¤‡æ•°æ®é›†

è¯·å°†æ•°æ®é›†ç»„ç»‡æˆä»¥ä¸‹ç›®å½•ç»“æ„ï¼ˆæˆ‘ä»¬ç§°è¿™ç§ç›®å½•ç»“æ„æ ·å¼ä¸º `vfm`ï¼‰ï¼Œè¿™ä¸åˆ†ç±»ä»»åŠ¡ç›¸åŒï¼š

```
.
â”œâ”€â”€ /XXX/FundusRegression/
â”‚   â”œâ”€â”€ dataset_A/
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”‚   â”œâ”€â”€ 1.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ training_labels.txt
â”‚   â”‚   â””â”€â”€ test_labels.txt
â”‚   â”œâ”€â”€ dataset_B/
â”‚   â”‚   â””â”€â”€ ....
â”‚   â””â”€â”€ ....
â”œâ”€â”€ /XXX/ExternalRegression/
â”‚   â”œâ”€â”€ dataset_A/
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”‚   â”œâ”€â”€ 1.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ training_labels.txt
â”‚   â”‚   â””â”€â”€ test_labels.txt
â”‚   â”œâ”€â”€ dataset_B/
â”‚   â”‚   â””â”€â”€ ....
â”‚   â””â”€â”€ ....
...
```

ç›¸åº”çš„ `training_labels.txt` å’Œ `test_labels.txt` ç»„ç»‡å¦‚ä¸‹ï¼ˆ38 ä¸ªå€¼ï¼‰ï¼š

```
# åœ¨ training_labels.txt ä¸­
training/1.jpg;38.8,2.5,37.0,11.4,8.9,0.05,0.4,0.13,1.1,46.6,157.0,3.87,31.3,32.8,337.0,..., 3.4,4.13,0.93,2.62,3.17
```

æˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆéšæœºæ•°æ®é›†ï¼š

```shell
python evaluation/random_data.py --task metric_reg --dst_dir ./dataset/metric_random
```

#### 3.6.2. æå–ç‰¹å¾

é¦–å…ˆï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æå–å›¾åƒç‰¹å¾ï¼š

```shell
# æå– Fundus å›¾åƒçš„ç‰¹å¾
CUDA_VISIBLE_DEVICES=0,1 nohup python3 -m torch.distributed.launch --nproc_per_node=2 --master_port=29503 evaluation/extract_features.py \
--pretrained_weights ./pretrain_weights/VFM_Fundus_weights.pth \
--batch_size_per_gpu 768 \
--data_path ./dataset/metric_random/FundusRegression \
--modality Fundus \
--dst_root ./dataset/metric_random/FunRegFeat/ > extract_feats.log 2>&1

#æå– External å›¾åƒçš„ç‰¹å¾
CUDA_VISIBLE_DEVICES=0,1 nohup python3 -m torch.distributed.launch --nproc_per_node=2 --master_port=29503 evaluation/extract_features.py \
--pretrained_weights ./pretrain_weights/VFM_External_weights.pth \
--batch_size_per_gpu 768 \
--data_path ./dataset/metric_random/ExternalRegression \
--modality External \
--dst_root ./dataset/metric_random/ExternalRegFeat/ > extract_feats.log 2>&1
```

#### 3.6.3. ä½¿ç”¨æå–çš„ç‰¹å¾è®­ç»ƒè§£ç å™¨

ç„¶åï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®­ç»ƒç”Ÿç‰©æ ‡å¿—ç‰©é¢„æµ‹è§£ç å™¨ï¼š

```shell
CUDA_VISIBLE_DEVICES=0,1 nohup python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=29504 evaluation/train_metric_reg_multi_decoder.py  \
--name train_metric_reg_multi \
--output_dir ./results \
--datasets FunRegFeat ExternalRegFeat \
--data_path ./dataset/metric_random/ \
--batch_size_per_gpu 4096 > train_metric_reg_multi.log 2>&1 &
```

### 3.7. è®­ç»ƒé’å…‰çœ¼è¿›å±•é¢„æµ‹è§£ç å™¨ \[å•æ¨¡æ€\]

#### 3.7.1 å‡†å¤‡æ•°æ®

è¯·å°†æ•°æ®ç»„ç»‡æˆä»¥ä¸‹ç»“æ„ï¼š

```

â”œâ”€â”€ /dataset/glaucoma_forecasting/
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ 1.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ 1.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ training_labels.txt
â”‚   â””â”€â”€ test_labels.txt
```

ç›¸åº”çš„ `training_labels.txt` å’Œ `test_labels.txt` ç»„ç»‡å¦‚ä¸‹ (path/to/image, label, time interval)ï¼š

```
# åœ¨ training_labels.txt ä¸­
./dataset/glaucoma_forecasting/training/1.jpg, 0, 309
# åœ¨ test_labels.txt ä¸­
./dataset/glaucoma_forecasting/test/1.jpg, 0, 690
```

#### 3.7.2 è®­ç»ƒè§£ç å™¨

é’å…‰çœ¼é¢„æµ‹è§£ç å™¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œè®­ç»ƒï¼š

```shell
CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch evaluation/train_forecasting_decoder.py  --data_path ./dataset/glaucoma_forecasting/ --pretrained_weights /path/to/checkpoint.pth --n_last_blocks 4 --avgpool_patchtokens 1 --input_size 224 --checkpoint_key teacher --output_dir ./results/glaucoma_forecasting --num_labels 2 --lr 0.001 --batch_size_per_gpu 128 --epochs 100
```

## 4\. VisionFM ç§æœ‰è¯„ä¼°æ•°æ®å’Œåˆæˆå›¾åƒ

å¯ä»¥è®¿é—®åˆæˆå›¾åƒå’Œæˆ‘ä»¬ç§æœ‰è¯„ä¼°æ•°æ®çš„ä¸€ä¸ªå­é›†ã€‚è¯·ä¸‹è½½ [æ•°æ®è¯·æ±‚å’Œåè®®è¡¨](resource/visionfm_dataset_agreement_form.pdf)ï¼Œç­¾ååå‘é€è‡³ visionfm-datasets@googlegroups.com

## è®¸å¯è¯

æœ¬é¡¹ç›®æ ¹æ®ä»…å…è®¸ç”¨äºç ”ç©¶å’Œæ•™è‚²ç›®çš„çš„è®¸å¯è¯å‘å¸ƒã€‚è¯¥æ¨¡å‹çš„å•†ä¸šä½¿ç”¨æ˜¯ä¸å…è®¸çš„ã€‚ä½¿ç”¨è¯¥æ¨¡å‹æ—¶ï¼Œè¯·ç¡®ä¿éµå®ˆæ­¤è®¸å¯è¯çš„æ¡æ¬¾ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æœ¬ä»“åº“ä¸­åŒ…å«çš„ LICENSE æ–‡ä»¶ã€‚

/